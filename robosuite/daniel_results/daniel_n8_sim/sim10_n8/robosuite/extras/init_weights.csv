policy,OrderedDict([('log_std', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.])), ('mlp_extractor.shared_net.0.weight', tensor([[-0.0028,  0.0104, -0.1668],
        [ 0.0341, -0.0622,  0.2257],
        [ 0.2837,  0.0180, -0.2427],
        [ 0.1507, -0.0910, -0.2697],
        [-0.3207,  0.3459, -0.0069],
        [ 0.4278,  0.0441,  0.3518],
        [ 0.2528, -0.1858, -0.4977],
        [ 0.1108,  0.0437, -0.3353],
        [-0.3837, -0.0911,  0.1115],
        [-0.1007,  0.2333,  0.2089],
        [ 0.0651,  0.3610,  0.3654],
        [-0.1933,  0.5375,  0.0193],
        [ 0.0718, -0.1668, -0.2604],
        [-0.0274,  0.4542,  0.1918],
        [ 0.1846, -0.3127,  0.3777],
        [-0.3006, -0.1714, -0.0283],
        [ 0.0184, -0.4784, -0.0606],
        [ 0.1671, -0.0212,  0.0646],
        [-0.2757, -0.1304, -0.1381],
        [ 0.2693,  0.1192,  0.0575],
        [-0.0517, -0.1324,  0.2040],
        [ 0.3990, -0.1897,  0.4936],
        [-0.1832,  0.2781, -0.1900],
        [ 0.0922,  0.2986, -0.1786],
        [-0.1498,  0.2515,  0.2695],
        [ 0.0801, -0.1272, -0.2685],
        [-0.1260,  0.0855, -0.2958],
        [-0.4150, -0.1466, -0.2405],
        [-0.3815, -0.0876,  0.2826],
        [-0.0965,  0.1964, -0.1604],
        [-0.4479, -0.5927,  0.2951],
        [ 0.5011, -0.0023, -0.0350]])), ('mlp_extractor.shared_net.0.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.])), ('mlp_extractor.shared_net.2.weight', tensor([[-0.3615,  0.3403,  0.2614,  ..., -0.0397, -0.3048, -0.1683],
        [ 0.0379,  0.2179, -0.0484,  ..., -0.1645, -0.1036,  0.3378],
        [ 0.5231,  0.2390, -0.4892,  ...,  0.1582,  0.0340,  0.2102],
        ...,
        [ 0.1657,  0.1020,  0.4008,  ..., -0.2366, -0.2745, -0.2045],
        [ 0.0834, -0.4519,  0.2357,  ..., -0.0294, -0.3847, -0.2006],
        [ 0.1972, -0.3480, -0.0116,  ..., -0.3343, -0.0622, -0.1328]])), ('mlp_extractor.shared_net.2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.])), ('action_net.weight', tensor([[ 0.0020,  0.0039,  0.0011,  ...,  0.0024,  0.0005, -0.0007],
        [-0.0007, -0.0001, -0.0021,  ..., -0.0018, -0.0001, -0.0001],
        [-0.0018, -0.0017,  0.0018,  ..., -0.0007, -0.0013, -0.0016],
        ...,
        [-0.0007,  0.0014, -0.0007,  ...,  0.0032,  0.0006, -0.0015],
        [-0.0018, -0.0012,  0.0037,  ..., -0.0003,  0.0035,  0.0014],
        [ 0.0003,  0.0025, -0.0033,  ..., -0.0023, -0.0017, -0.0006]])), ('action_net.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0.])), ('value_net.weight', tensor([[-0.2795, -0.0509, -0.0502, -0.3114,  0.1146, -0.1927, -0.1407, -0.0774,
         -0.1086, -0.4046,  0.1196,  0.0111,  0.2169, -0.0169,  0.0547, -0.1166,
          0.2913,  0.1044, -0.2239, -0.3463,  0.0116, -0.2553, -0.0939,  0.3152,
         -0.0732,  0.1569,  0.0165, -0.0779,  0.0279, -0.0100, -0.1159, -0.0043]])), ('value_net.bias', tensor([0.]))])
policy.optimizer,{'state': {}, 'param_groups': [{'lr': 0.0003, 'betas': (0.9, 0.999), 'eps': 1e-05, 'weight_decay': 0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8]}]}
